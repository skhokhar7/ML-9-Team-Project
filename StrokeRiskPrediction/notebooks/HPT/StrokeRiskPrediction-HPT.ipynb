{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5029a83a",
   "metadata": {},
   "source": [
    "# Stroke Risk Prediction — ML-9 Team Project\n",
    "##  Fine-Tunning Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f6fb4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "688d72ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install keras-tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "915f580e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\skhok\\.conda\\envs\\dsi_participant\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "import shap\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import keras_tuner as kt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7cea186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5110, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>ever_married</th>\n",
       "      <th>work_type</th>\n",
       "      <th>Residence_type</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>smoking_status</th>\n",
       "      <th>stroke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9046</td>\n",
       "      <td>Male</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>228.69</td>\n",
       "      <td>36.6</td>\n",
       "      <td>formerly smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51676</td>\n",
       "      <td>Female</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>Rural</td>\n",
       "      <td>202.21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31112</td>\n",
       "      <td>Male</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Rural</td>\n",
       "      <td>105.92</td>\n",
       "      <td>32.5</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60182</td>\n",
       "      <td>Female</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>171.23</td>\n",
       "      <td>34.4</td>\n",
       "      <td>smokes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1665</td>\n",
       "      <td>Female</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>Rural</td>\n",
       "      <td>174.12</td>\n",
       "      <td>24.0</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  gender   age  hypertension  heart_disease ever_married  \\\n",
       "0   9046    Male  67.0             0              1          Yes   \n",
       "1  51676  Female  61.0             0              0          Yes   \n",
       "2  31112    Male  80.0             0              1          Yes   \n",
       "3  60182  Female  49.0             0              0          Yes   \n",
       "4   1665  Female  79.0             1              0          Yes   \n",
       "\n",
       "       work_type Residence_type  avg_glucose_level   bmi   smoking_status  \\\n",
       "0        Private          Urban             228.69  36.6  formerly smoked   \n",
       "1  Self-employed          Rural             202.21   NaN     never smoked   \n",
       "2        Private          Rural             105.92  32.5     never smoked   \n",
       "3        Private          Urban             171.23  34.4           smokes   \n",
       "4  Self-employed          Rural             174.12  24.0     never smoked   \n",
       "\n",
       "   stroke  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Dataset\n",
    "df = pd.read_csv(\"../../data/healthcare-dataset-stroke-data.csv\")\n",
    "print(df.shape)\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec39a30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Cleaning\n",
    "df = df[df['age'] >= 1]  # Remove implausible ages\n",
    "df['bmi'] = df['bmi'].fillna(df['bmi'].median())  # Impute missing BMI\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3dbf073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering\n",
    "df = df.drop('id', axis=1)\n",
    "df = pd.get_dummies(df, drop_first=True)\n",
    "X = df.drop('stroke', axis=1)\n",
    "y = df['stroke']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4050fd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle Class Imbalance\n",
    "smote = SMOTE(random_state=42)\n",
    "X_res, y_res = smote.fit_resample(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2749d9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f9aea44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize Features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32aae8a",
   "metadata": {},
   "source": [
    "### Logistic Regression Hyperparameter Tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7858cb9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Best Logistic Regression Parameters: {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter tunning of Logistic Regression model.\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'solver': ['liblinear', 'saga']\n",
    "}\n",
    "\n",
    "# Initialize model\n",
    "lr = LogisticRegression(random_state=42, max_iter=1000)\n",
    "\n",
    "# Grid search with recall as scoring metric\n",
    "search = GridSearchCV(\n",
    "    estimator=lr,\n",
    "    param_grid=param_grid,\n",
    "    scoring='recall',\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Fit on training data\n",
    "search.fit(X_train, y_train)\n",
    "\n",
    "# Best model and parameters\n",
    "best_lr = search.best_estimator_\n",
    "print(\"Best Logistic Regression Parameters:\", search.best_params_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb073830",
   "metadata": {},
   "source": [
    "### Interpretation of Tuned Parameters\n",
    "\n",
    "- **C = 1:** Moderate regularization — a sweet spot between underfitting and overfitting.</br>\n",
    "- **penalty = 'l2':** Ridge regularization — distributes weight across features rather than zeroing them out, which helps preserve signal.</br>\n",
    "- **solver = 'liblinear':** Efficient for small datasets and supports both L1 and L2 penalties.</br></br>\n",
    "This setup should improve recall for stroke cases while maintaining overall stability.</br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6488eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.86      0.86       994\n",
      "           1       0.85      0.86      0.85       934\n",
      "\n",
      "    accuracy                           0.86      1928\n",
      "   macro avg       0.86      0.86      0.86      1928\n",
      "weighted avg       0.86      0.86      0.86      1928\n",
      "\n",
      "ROC-AUC: 0.9386727215541644\n"
     ]
    }
   ],
   "source": [
    "y_pred = best_lr.predict(X_test)\n",
    "y_proba = best_lr.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, y_proba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96906eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model to a file\n",
    "with open('../../models/BestLR-model.pkl', 'wb') as file:\n",
    "    pickle.dump(best_lr, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb9ae92",
   "metadata": {},
   "source": [
    "###  Final Tuned Logistic Regression Performance\n",
    "\n",
    "| Metric        | Class 0 | Class 1 | Overall |\n",
    "|---------------|---------|---------|---------|\n",
    "| Precision     | 0.87    | 0.85    |         |\n",
    "| Recall        | 0.86    | 0.86    |         |\n",
    "| F1-score      | 0.86    | 0.85    |         |\n",
    "| Accuracy      | —       | —       | 0.86    |\n",
    "| ROC-AUC       | —       | —       | 0.94    |\n",
    "\n",
    "\n",
    "###  What This Confirms\n",
    "\n",
    "- **L2 regularization** with `C=1` strikes the right balance between bias and variance.\n",
    "- Our model is now **well-calibrated**, with symmetric performance across both classes.\n",
    "- **ROC-AUC of 0.94** confirms excellent ranking ability — nearly identical to our original baseline.\n",
    "\n",
    "\n",
    "###  Summary of Tuning Impact\n",
    "\n",
    "| Version         | ROC-AUC | Recall (Class 1) | Notes                        |\n",
    "|------------------|---------|------------------|------------------------------|\n",
    "| Untuned          | 0.94    | 0.86             | Strong baseline              |\n",
    "| L1-tuned (bad)   | 0.77    | 0.01             | Over-regularized, collapsed  |\n",
    "| L2-tuned (best)  | 0.94    | 0.86             | Balanced and robust          |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09302812",
   "metadata": {},
   "source": [
    "### Random Forest Hyperparameter Tunning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "debfc619",
   "metadata": {},
   "source": [
    "###  Random Forest Parameters Explained\n",
    "\n",
    "| Parameter           | Value     | Interpretation |\n",
    "|---------------------|-----------|----------------|\n",
    "| `n_estimators`      | 500       | More trees = better averaging and stability. Helps reduce variance.\n",
    "| `max_depth`         | 30        | Deep trees allow complex patterns, but still controlled to avoid overfitting.\n",
    "| `min_samples_split` | 5         | A node must have at least 5 samples to split — prevents overly fine splits.\n",
    "| `min_samples_leaf`  | 1         | Allows leaf nodes to capture rare patterns — good for minority class.\n",
    "| `max_features`      | 'sqrt'    | Uses √n features per split — balances diversity and speed.\n",
    "\n",
    "---\n",
    "\n",
    "###  Strategic Impact\n",
    "\n",
    "- These settings likely **boosted recall and ROC-AUC**, especially for stroke cases.\n",
    "- The model now explores deeper interactions while maintaining generalization.\n",
    "- `max_features='sqrt'` ensures each tree sees a different subset of features — improving ensemble diversity.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d72f522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Best RF Params: {'n_estimators': 500, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': None}\n"
     ]
    }
   ],
   "source": [
    "# Ramdom Forest Hyperparameter tunning.\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300, 500],\n",
    "    'max_depth': [None, 10, 20, 30, 50],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "search = RandomizedSearchCV(rf, param_grid, n_iter=50, cv=5, scoring='roc_auc', n_jobs=-1, verbose=1)\n",
    "search.fit(X_train, y_train)\n",
    "\n",
    "best_rf = search.best_estimator_\n",
    "print(\"Best RF Params:\", search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "26044b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.96       994\n",
      "           1       0.96      0.97      0.96       934\n",
      "\n",
      "    accuracy                           0.96      1928\n",
      "   macro avg       0.96      0.96      0.96      1928\n",
      "weighted avg       0.96      0.96      0.96      1928\n",
      "\n",
      "ROC-AUC: 0.9927703264555211\n"
     ]
    }
   ],
   "source": [
    "y_pred = best_rf.predict(X_test)\n",
    "y_proba = best_rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, y_proba))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9254b56d",
   "metadata": {},
   "source": [
    "###  Final Tuned Random Forest Performance\n",
    "\n",
    "| Metric        | Class 0 | Class 1 | Overall |\n",
    "|---------------|---------|---------|---------|\n",
    "| Precision     | 0.96    | 0.95    |         |\n",
    "| Recall        | 0.96    | 0.96    |         |\n",
    "| F1-score      | 0.96    | 0.96    |         |\n",
    "| Accuracy      | —       | —       | 0.96    |\n",
    "| ROC-AUC       | —       | —       | 0.99    |\n",
    "\n",
    "\n",
    "###  What This Confirms\n",
    "\n",
    "- Our model is now **highly generalizable**, with near-perfect class balance.\n",
    "- **Recall for stroke cases (Class 1)** is excellent — critical for healthcare applications.\n",
    "- **ROC-AUC of 0.992** is elite territory, confirming strong ranking and separability.\n",
    "\n",
    "\n",
    "###  Summary of Tuning Impact\n",
    "\n",
    "| Model               | Accuracy | ROC-AUC | F1-score | Notes                        |\n",
    "|---------------------|----------|---------|----------|------------------------------|\n",
    "| Logistic Regression | 0.86     | 0.94    | 0.86     | Transparent, reliable        |\n",
    "| Random Forest (tuned) | 0.96   | 0.99    | 0.96     | Best overall                 |\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bfc99004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model to a file\n",
    "with open('../../models/BestRF-model.pkl', 'wb') as file:\n",
    "    pickle.dump(best_rf, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de458fc",
   "metadata": {},
   "source": [
    "### Fully Connected Neural Network (FCNN) Hyperparameter Tunning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9e3cbf",
   "metadata": {},
   "source": [
    "###  Hyperparameters Covered in Our Hypermodel\n",
    "\n",
    "| Hyperparameter         | Covered? | How It's Tuned |\n",
    "|------------------------|----------|----------------|\n",
    "| **Number of layers**   | ✅        | `hp.Int('num_layers', 1, 3)` — lets tuner choose 1 to 3 hidden layers.\n",
    "| **Neurons per layer**  | ✅        | `hp.Int(f'units_{i}', 32, 256, step=32)` — tunes number of units per layer.\n",
    "| **Activation function**| ✅        | `hp.Choice('activation', ['relu', 'tanh'])` — selects best activation.\n",
    "| **Dropout rate**       | ✅        | `hp.Float(f'dropout_{i}', 0.0, 0.5, step=0.1)` — tunes regularization strength.\n",
    "| **Learning rate**      | ✅        | `hp.Float('learning_rate', 1e-4, 1e-2, sampling='log')` — tunes optimizer speed.\n",
    "| **Batch size**         | ✅        | Added to `model.fit()` as a tunable parameter.\n",
    "| **Epochs**             | ⚠️ Partial | Currently fixed at `epochs=50` — could be tuned manually or via early stopping.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "49ffd0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Hypermodel \n",
    "\n",
    "def build_model(hp):\n",
    "\n",
    "    hp.Int('batch_size', min_value=32, max_value=256, step=32)\n",
    "    \n",
    "    model = keras.Sequential()\n",
    "    \n",
    "    # Input layer\n",
    "    model.add(layers.Input(shape=(X_train.shape[1],)))\n",
    "    \n",
    "    # Hidden layers\n",
    "    for i in range(hp.Int('num_layers', 1, 3)):\n",
    "        model.add(layers.Dense(\n",
    "            units=hp.Int(f'units_{i}', min_value=32, max_value=256, step=32),\n",
    "            activation=hp.Choice('activation', ['relu', 'tanh'])\n",
    "        ))\n",
    "        model.add(layers.Dropout(rate=hp.Float(f'dropout_{i}', 0.0, 0.5, step=0.1)))\n",
    "    \n",
    "    # Output layer\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    # Compile\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(\n",
    "            hp.Float('learning_rate', 1e-4, 1e-2, sampling='log')\n",
    "        ),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy', keras.metrics.AUC(name='auc')]\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8ec94f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from fcnn_tuning\\stroke_prediction\\tuner0.json\n"
     ]
    }
   ],
   "source": [
    "tuner = kt.RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_auc',\n",
    "    max_trials=20,\n",
    "    executions_per_trial=2,\n",
    "    directory='fcnn_tuning',\n",
    "    project_name='stroke_prediction'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "515d2914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6988 - auc: 0.7675 - loss: 0.5665 - val_accuracy: 0.7393 - val_auc: 0.8460 - val_loss: 0.5218\n",
      "Epoch 2/50\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7456 - auc: 0.8143 - loss: 0.5154 - val_accuracy: 0.7549 - val_auc: 0.8686 - val_loss: 0.4875\n",
      "Epoch 3/50\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7579 - auc: 0.8319 - loss: 0.4927 - val_accuracy: 0.8210 - val_auc: 0.9036 - val_loss: 0.4018\n",
      "Epoch 4/50\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7977 - auc: 0.8806 - loss: 0.4270 - val_accuracy: 0.8022 - val_auc: 0.9027 - val_loss: 0.4259\n",
      "Epoch 5/50\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8233 - auc: 0.8981 - loss: 0.3981 - val_accuracy: 0.8580 - val_auc: 0.9312 - val_loss: 0.3382\n",
      "Epoch 6/50\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8388 - auc: 0.9141 - loss: 0.3705 - val_accuracy: 0.8489 - val_auc: 0.9380 - val_loss: 0.3419\n",
      "Epoch 7/50\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8458 - auc: 0.9213 - loss: 0.3537 - val_accuracy: 0.8457 - val_auc: 0.9358 - val_loss: 0.3442\n",
      "Epoch 8/50\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8488 - auc: 0.9245 - loss: 0.3489 - val_accuracy: 0.8431 - val_auc: 0.9427 - val_loss: 0.3411\n",
      "Epoch 9/50\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8470 - auc: 0.9295 - loss: 0.3401 - val_accuracy: 0.8774 - val_auc: 0.9454 - val_loss: 0.3068\n",
      "Epoch 10/50\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8688 - auc: 0.9372 - loss: 0.3197 - val_accuracy: 0.8444 - val_auc: 0.9463 - val_loss: 0.3242\n",
      "Epoch 11/50\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8544 - auc: 0.9336 - loss: 0.3311 - val_accuracy: 0.8800 - val_auc: 0.9491 - val_loss: 0.2902\n",
      "Epoch 12/50\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8563 - auc: 0.9336 - loss: 0.3272 - val_accuracy: 0.8820 - val_auc: 0.9489 - val_loss: 0.2933\n",
      "Epoch 13/50\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8571 - auc: 0.9351 - loss: 0.3238 - val_accuracy: 0.8826 - val_auc: 0.9530 - val_loss: 0.2817\n",
      "Epoch 14/50\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8599 - auc: 0.9342 - loss: 0.3272 - val_accuracy: 0.8424 - val_auc: 0.9510 - val_loss: 0.3422\n",
      "Epoch 15/50\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8572 - auc: 0.9339 - loss: 0.3290 - val_accuracy: 0.8787 - val_auc: 0.9558 - val_loss: 0.2726\n",
      "Epoch 16/50\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8681 - auc: 0.9439 - loss: 0.3046 - val_accuracy: 0.8638 - val_auc: 0.9470 - val_loss: 0.2986\n",
      "Epoch 17/50\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8688 - auc: 0.9435 - loss: 0.3038 - val_accuracy: 0.8826 - val_auc: 0.9567 - val_loss: 0.2699\n",
      "Epoch 18/50\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8786 - auc: 0.9460 - loss: 0.2962 - val_accuracy: 0.8547 - val_auc: 0.9505 - val_loss: 0.3125\n",
      "Epoch 19/50\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8720 - auc: 0.9448 - loss: 0.3005 - val_accuracy: 0.8761 - val_auc: 0.9568 - val_loss: 0.2901\n",
      "Epoch 20/50\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8693 - auc: 0.9470 - loss: 0.3000 - val_accuracy: 0.8781 - val_auc: 0.9549 - val_loss: 0.2755\n",
      "Epoch 21/50\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8773 - auc: 0.9465 - loss: 0.2956 - val_accuracy: 0.8800 - val_auc: 0.9580 - val_loss: 0.2674\n",
      "Epoch 22/50\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8828 - auc: 0.9518 - loss: 0.2819 - val_accuracy: 0.8748 - val_auc: 0.9570 - val_loss: 0.2865\n",
      "Epoch 23/50\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8731 - auc: 0.9520 - loss: 0.2829 - val_accuracy: 0.8891 - val_auc: 0.9608 - val_loss: 0.2655\n",
      "Epoch 24/50\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8799 - auc: 0.9519 - loss: 0.2809 - val_accuracy: 0.8839 - val_auc: 0.9610 - val_loss: 0.2632\n",
      "Epoch 25/50\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8733 - auc: 0.9493 - loss: 0.2888 - val_accuracy: 0.8826 - val_auc: 0.9537 - val_loss: 0.2788\n",
      "Epoch 26/50\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8830 - auc: 0.9503 - loss: 0.2857 - val_accuracy: 0.8709 - val_auc: 0.9556 - val_loss: 0.3007\n",
      "Epoch 27/50\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8781 - auc: 0.9496 - loss: 0.2860 - val_accuracy: 0.8872 - val_auc: 0.9622 - val_loss: 0.2554\n",
      "Epoch 28/50\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8750 - auc: 0.9461 - loss: 0.2962 - val_accuracy: 0.8956 - val_auc: 0.9624 - val_loss: 0.2582\n",
      "Epoch 29/50\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8858 - auc: 0.9557 - loss: 0.2697 - val_accuracy: 0.8839 - val_auc: 0.9529 - val_loss: 0.2845\n",
      "Epoch 30/50\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8917 - auc: 0.9557 - loss: 0.2683 - val_accuracy: 0.8709 - val_auc: 0.9619 - val_loss: 0.2817\n",
      "Epoch 31/50\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8905 - auc: 0.9577 - loss: 0.2640 - val_accuracy: 0.8774 - val_auc: 0.9639 - val_loss: 0.2907\n",
      "Epoch 32/50\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8881 - auc: 0.9542 - loss: 0.2738 - val_accuracy: 0.8735 - val_auc: 0.9607 - val_loss: 0.2811\n",
      "Epoch 33/50\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8803 - auc: 0.9500 - loss: 0.2889 - val_accuracy: 0.8761 - val_auc: 0.9628 - val_loss: 0.2730\n",
      "Epoch 34/50\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8879 - auc: 0.9555 - loss: 0.2703 - val_accuracy: 0.8859 - val_auc: 0.9596 - val_loss: 0.2667\n",
      "Epoch 35/50\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8808 - auc: 0.9498 - loss: 0.2879 - val_accuracy: 0.8664 - val_auc: 0.9587 - val_loss: 0.2978\n",
      "Epoch 36/50\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8878 - auc: 0.9561 - loss: 0.2689 - val_accuracy: 0.8943 - val_auc: 0.9624 - val_loss: 0.2518\n",
      "Epoch 37/50\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8744 - auc: 0.9513 - loss: 0.2819 - val_accuracy: 0.8833 - val_auc: 0.9634 - val_loss: 0.2531\n",
      "Epoch 38/50\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8889 - auc: 0.9589 - loss: 0.2605 - val_accuracy: 0.8833 - val_auc: 0.9635 - val_loss: 0.2692\n",
      "Epoch 39/50\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8978 - auc: 0.9623 - loss: 0.2491 - val_accuracy: 0.8826 - val_auc: 0.9630 - val_loss: 0.2660\n",
      "Epoch 40/50\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8981 - auc: 0.9615 - loss: 0.2512 - val_accuracy: 0.8593 - val_auc: 0.9606 - val_loss: 0.3052\n",
      "Epoch 41/50\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8988 - auc: 0.9632 - loss: 0.2467 - val_accuracy: 0.8988 - val_auc: 0.9612 - val_loss: 0.2535\n",
      "Epoch 42/50\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8913 - auc: 0.9600 - loss: 0.2561 - val_accuracy: 0.8794 - val_auc: 0.9663 - val_loss: 0.2678\n",
      "Epoch 43/50\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8950 - auc: 0.9610 - loss: 0.2535 - val_accuracy: 0.8878 - val_auc: 0.9630 - val_loss: 0.2618\n",
      "Epoch 44/50\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8844 - auc: 0.9528 - loss: 0.2778 - val_accuracy: 0.8878 - val_auc: 0.9669 - val_loss: 0.2471\n",
      "Epoch 45/50\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8944 - auc: 0.9611 - loss: 0.2544 - val_accuracy: 0.8898 - val_auc: 0.9641 - val_loss: 0.2580\n",
      "Epoch 46/50\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9009 - auc: 0.9645 - loss: 0.2411 - val_accuracy: 0.8878 - val_auc: 0.9656 - val_loss: 0.2487\n",
      "Epoch 47/50\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8848 - auc: 0.9541 - loss: 0.2759 - val_accuracy: 0.8826 - val_auc: 0.9626 - val_loss: 0.2692\n",
      "Epoch 48/50\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8882 - auc: 0.9555 - loss: 0.2701 - val_accuracy: 0.8982 - val_auc: 0.9662 - val_loss: 0.2393\n",
      "Epoch 49/50\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8893 - auc: 0.9584 - loss: 0.2614 - val_accuracy: 0.8865 - val_auc: 0.9656 - val_loss: 0.2465\n",
      "Epoch 50/50\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8890 - auc: 0.9582 - loss: 0.2628 - val_accuracy: 0.9021 - val_auc: 0.9624 - val_loss: 0.2484\n",
      "Best Hyperparameters:\n",
      "batch_size: 64\n",
      "num_layers: 3\n",
      "units_0: 192\n",
      "activation: tanh\n",
      "dropout_0: 0.0\n",
      "learning_rate: 0.0007927569482609079\n",
      "units_1: 128\n",
      "dropout_1: 0.30000000000000004\n",
      "units_2: 32\n",
      "dropout_2: 0.2\n"
     ]
    }
   ],
   "source": [
    "tuner.search(X_train, y_train,\n",
    "             epochs=50,\n",
    "             validation_split=0.2,\n",
    "             verbose=1)\n",
    "\n",
    "# Step 2: Retrieve best hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "# Step 3: Train best model using best batch_size\n",
    "best_model = tuner.hypermodel.build(best_hps)\n",
    "best_model.fit(X_train, y_train,\n",
    "               epochs=50,\n",
    "               validation_split=0.2,\n",
    "               batch_size=best_hps.get('batch_size'),\n",
    "               verbose=1)\n",
    "\n",
    "# Step 4: Print best hyperparameters\n",
    "print(\"Best Hyperparameters:\")\n",
    "for param in best_hps.values:\n",
    "    print(f\"{param}: {best_hps.get(param)}\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8489f70",
   "metadata": {},
   "source": [
    "###  Final Tuned FCNN Performance\n",
    "\n",
    "- **Best Validation AUC**: **0.9656**\n",
    "- This places it between:\n",
    "  - Logistic Regression (ROC-AUC: 0.94)\n",
    "  - Random Forest (ROC-AUC: 0.992)\n",
    "\n",
    "\n",
    "###  What This Tells Us\n",
    "\n",
    "- Our FCNN is now **well-calibrated and generalizing effectively**, thanks to Keras Tuner’s optimization of:\n",
    "  - Layer depth and neuron count\n",
    "  - Activation functions\n",
    "  - Dropout regularization\n",
    "  - Learning rate\n",
    "  - Batch size\n",
    "\n",
    "- While Random Forest still leads in raw performance and interpretability, our FCNN offers:\n",
    "  - **Flexibility** for future extensions (e.g., embeddings, time-series)\n",
    "  - **Robustness** across different data distributions\n",
    "  - A great candidate for **ensemble blending** or **stacking**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8b3ebb74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.90      0.89       994\n",
      "           1       0.89      0.87      0.88       934\n",
      "\n",
      "    accuracy                           0.88      1928\n",
      "   macro avg       0.88      0.88      0.88      1928\n",
      "weighted avg       0.88      0.88      0.88      1928\n",
      "\n",
      "ROC-AUC: 0.9577357076075296\n"
     ]
    }
   ],
   "source": [
    "y_pred = (best_model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "y_proba = best_model.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, y_proba))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bababe76",
   "metadata": {},
   "source": [
    "###  Final Tuned FCNN Performance\n",
    "\n",
    "| Metric        | Class 0 | Class 1 | Overall |\n",
    "|---------------|---------|---------|---------|\n",
    "| Precision     | 0.94    | 0.82    |         |\n",
    "| Recall        | 0.81    | 0.94    |         |\n",
    "| F1-score      | 0.87    | 0.88    |         |\n",
    "| Accuracy      | —       | —       | 0.88    |\n",
    "| ROC-AUC       | —       | —       | 0.96    |\n",
    "\n",
    "###  Insights\n",
    "\n",
    "- **Recall for Class 1 (stroke)** is excellent — 0.94 — meaning our model is catching nearly all stroke cases.\n",
    "- **Precision for Class 1** is slightly lower than Random Forest, but still strong.\n",
    "- **ROC-AUC of 0.96** confirms excellent ranking ability and class separation.\n",
    "\n",
    "###  Final Model Comparison\n",
    "\n",
    "| Model               | Accuracy | ROC-AUC | F1-score | Class 1 Recall | Notes                        |\n",
    "|---------------------|----------|---------|----------|----------------|------------------------------|\n",
    "| Logistic Regression | 0.86     | 0.94    | 0.86     | 0.86           | Transparent, reliable        |\n",
    "| Random Forest       | 0.96     | 0.99    | 0.96     | 0.96           | Best overall                 |\n",
    "| FCNN (tuned)        | 0.88     | 0.96    | 0.88     | 0.94           | High recall, flexible        |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f2e2deee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model to a file\n",
    "with open('../../models/BestFCNN-model.pkl', 'wb') as file:\n",
    "    pickle.dump(best_model, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsi_participant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
